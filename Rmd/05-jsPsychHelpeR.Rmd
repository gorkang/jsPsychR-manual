# jsPsychHelpeR {#jsPsychHelpeR}

---  

[![](img/GitHub32.png) jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR): Standardize and automatize data preparation and analysis of jsPsych experiments created with jsPsychMaker.

---  

jsPsychHelpeR will lend you a hand automatizing and standardizing your data preparation and analysis.

- Use a completely open, reproducible and automatic process to prepare your data

- Data preparation ready for > 50 tasks (see [here the list of tasks](https://github.com/gorkang/jsPsychMaker/blob/main/canonical_protocol/canonical_protocol_details.csv))

- Get tidy output dataframes for each task, and tidy general dataframes for the whole protocol

- Include tests for common issues

- Automatic reports with progress, descriptives, codebook, etc.

---  

**See [QuickGuide](#QuickGuidejsPsychHelpeR) for basic instructions.**

---  


## How to prepare data

Every [jsPsychMaker](https://github.com/gorkang/jsPsychMaker) task has a sister script on [jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR) to help prepare the data automatically. `run_initial_setup()` will try to make sure you have all the dependencies, folders, etc., and a customized `_targets.R` file adapted to your protocol, so data preparation can run automagically.  

---   

We use the {targets} (<https://github.com/wlandau/targets>) package.

**The whole process can be reproduced running `targets::tar_make()`**  

A nice visualization of all the pre-processing steps can be seen with `targets::tar_visnetwork(targets_only = TRUE)`  

The file `_targets.R` contains the important parameters and calls to all the functions used when running `targets::tar_make()`  


To see more detail about any specific step, you can:

1.  Go to the relevant function  

2.  Load the input parameters of the function with `debug_function(NAME_OF FUNCTION)`. Alternatively, manually use `targets::tar_load(NAME_OF_TARGET)`  

3.  Run the code step by step as you would normally do


## Basics

[jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR) uses as input a data created with a [jsPsychMaker](https://github.com/gorkang/jsPsychMaker) experimental protocol.   


### Inputs  

The input data folder will be named after the protocol_id, for example `999/` and needs to be placed in the `data/` folder of the jsPsychHelpeR project:    

- The data folder can contain either multiple .csv files, or a single .zip file

There will be a single .csv file for each participant and task of the protocol. For example:  

- 999_Consent_original_2022-04-02T205622_1.csv: [project: 999]_[experimento: Consent]_[version: original]_[datetime: 2022-04-02T205622]_[participant id: 1]


### Outputs

When the pipeline successfully runs with  `targets::tar_make()`, a number of outputs will be created.

All the outputs can be found in the `/outputs` folder. The only exception is the sensitive data and reports, which can be found in `.vault/outputs`.  


#### Output folders

The outputs will be organized in different folders:

- **Dataframes** for different stages of data processing can be found in `outputs/data`  

- **Files for manual correction** are in `outputs/data/manual_correction`

- **Plots**, **tables** and **reports** are in `outputs/plots`, `outputs/tables`and `outputs/reports` respectively.

- **Test outputs** are in `outputs/tests_outputs`

- **Anonymized Raw data**  will be moved to `.vault/data_vault/`  


#### Output dataframes

There will be a single data frame (df) for each of the tasks in `outputs/data`, plus a data frame (DF) for each of the steps of the data preparation, and a diccionary file listing all the available tasks. We store the files in two formats, csv and rds:  

- **DF_raw.csv**: All the `data/project_id/` csv files combined on a single file. We only add the columns  "project", "experimento", "version", "datetime", "id" by parsing the filenames  

- **DF_clean.csv**: Clean version of the raw file ready to process the individual tasks  

- **df_ShortNameOfTask.csv**: One df for each of the tasks of the protocol after being processed with the `prepare_ShortNameOfTask()` functions

- **DF_joined.csv**: all the processed tasks joined in a single DF

- **DF_analysis**: only the total scores and dimensions from `DF_joined` (columns ending in `_DIRt` `_STDt` `_DIRd` `STDd`)  

- **DICCIONARY_tasks.csv**: list of all tasks in the protocol  


#### Output files standards

All the output processed files columns are named in a standardized way:  

- **ShortNameOfTask_ItemNumber_RAW**: raw responses of participants for individual items  

- **ShortNameOfTask_ItemNumber_DIR**: processed raw responses following the task correction instructions (e.g. inverting certain items, converting strings to numbers, computing accuracy...)   

- **ShortNameOfTask_RAW_NA**:  number of missing data (NA) in the RAW responses  

- **ShortNameOfTask_DIR_NA**:  number of missing data (NA) in the DIR responses. If it is not equal to `ShortNameOfTask_RAW_NA` there is something wrong in the items correction.  

- **ShortNameOfTask_NameDimension_DIRd**: scores for a specific dimension (`d`) in a task, calculated following task correction instructions (e.g. summing or averaging certain items)  

- **ShortNameOfTask_NameDimension_STDd**: standardized score for a dimension (`d`)  

- **ShortNameOfTask_DIRt**: total (`t`) score for a task calculated following task correction instructions (e.g. summing or averaging all items)  

- **ShortNameOfTask_STDt**: standardized (`t`) score for a task  



## Create your own reports

You can use any of the template reports in the `_targets.R` file, or create your own reports.  

We will start opening one of the template reports: `rstudioapi::navigateToFile("doc/report_analysis.Rmd")`.

- Edit the RMarkdown file to adapt it to your needs. 

- If you already did `targets::tar_make()`, when running `targets::tar_load(DF_analysis)` the dataframe `DF_analysis` will load in your Environment.


Go back to the `_targets.R` file:

- Look for `# Analysis report` and uncomment the following lines:

```
  # tar_render(report_analysis, "doc/report_analysis.Rmd",
  #            output_file = paste0("../outputs/reports/report_analysis.html")),
```

When you finished editing and uncomented the tar_render command, go back to the `run.R` file:

- `targets::tar_make()`


## Create new tasks

To create the correction script for a new task, you should do:

- `create_new_task(short_name_task = "NAMETASK")`

This will create a new file from a template correction script (`R_tasks/prepare_TEMPLATE.R`) and adapt it to your `short_name_task` to make everything as standardized as possible.  

All the `prepare_NAMEOFTASK.R` scripts on the `R_tasks/` folder have been created using the same template.  


When you finish implementing the correction script, please do a [Pull request](https://github.com/gorkang/jsPsychHelpeR/pulls) so we can add you script to the pool, and help us filling up details about the task in the [NEW tasks document](https://docs.google.com/spreadsheets/d/1LAsyTZ2ZRP_xLiUBkqmawwnKWgy8OCwq4mmWrrc_rpQ/edit#gid=0).



## DEBUG tasks

At the begining of each of the `R_tasks/prepare_NAMETASK.R` scripts you will find a commented `debug_function(prepare_NAMETASK)` line.

When running it, it will load the input parameters for the task. From there, you can work inside of the preparation scipt as you would normally do in a R script.

If you get the error "Error in debug_function(prepare_NAMETASK) : could not find function 'debug_function' `debug_function()` does nor work" you will need to load all the functions in the `R/` folder first.

You can do this in one of three ways:

  - `CONTROL + P` shortcut will work if the `run_initial_setup()` completed correctly (at least on Ubuntu systems).
  
  - Run `targets::tar_load_globals()`
  
  - Or directly, source all the scripts in the `R/` folder: `invisible(lapply(list.files("./R", full.names = TRUE, pattern = ".R$"), source))`




## Technical aspects

### How trialid's are processed

See `PRFBM`:

- If more than one response per screen
    + Item: `PRFBM_04`
    + Responses: `{"daño":"Parcialmente en desacuerdo","beneficio":"Parcialmente en desacuerdo"}`
    + final trialids: `PRFBM_04_beneficio` and `PRFBM_04_daño`


## Common ERRORS

### `run_initial_setup()`:  

```
x Can find server credentials in '.vault/.credentials'
x 0 tasks found for protocol 'TU NUMERO DE PROYECTO'. NOT creating _targets.R file
```

#### On Linux (Ubuntu):

- IF you have the server credentials: 

  + Open .credentials_TEMPLATE `rstudioapi::navigateToFile(".vault/.credentials_TEMPLATE")`
  
  + Edit the file with your server credentials
  
  + Rename the file  to `.credentials`
  
---  

  
- IF you DON'T have the credentials but you have the .csv results files:

  + Copy the csv files to the folder `data/YOUR_PROJECT_NUMBER`
  
  + Run again `run_initial_setup()`


### On Mac or Windows:

  + Copy the csv files to the folder `data/YOUR_PROJECT_NUMBER`
  
  + Run again `run_initial_setup()`